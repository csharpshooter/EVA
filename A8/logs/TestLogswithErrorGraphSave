/home/abhijit/.virtualenvs/dl4cv/bin/python /snap/pycharm-professional/183/plugins/python/helpers/pydev/pydevconsole.py --mode=client --port=40063
import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/abhijit/EVARepo/EVA/A8'])
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.11.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.11.1
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0] on linux
runfile('/home/abhijit/EVARepo/EVA/A8/a8.py', wdir='/home/abhijit/EVARepo/EVA/A8')
Files already downloaded and verified
Files already downloaded and verified
CUDA Available? True
128
cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,728
       BatchNorm2d-2           [-1, 64, 32, 32]             128
            Conv2d-3           [-1, 64, 32, 32]          36,864
       BatchNorm2d-4           [-1, 64, 32, 32]             128
            Conv2d-5           [-1, 64, 32, 32]          36,864
       BatchNorm2d-6           [-1, 64, 32, 32]             128
        BasicBlock-7           [-1, 64, 32, 32]               0
            Conv2d-8           [-1, 64, 32, 32]          36,864
       BatchNorm2d-9           [-1, 64, 32, 32]             128
           Conv2d-10           [-1, 64, 32, 32]          36,864
      BatchNorm2d-11           [-1, 64, 32, 32]             128
       BasicBlock-12           [-1, 64, 32, 32]               0
           Conv2d-13          [-1, 128, 16, 16]          73,728
      BatchNorm2d-14          [-1, 128, 16, 16]             256
           Conv2d-15          [-1, 128, 16, 16]         147,456
      BatchNorm2d-16          [-1, 128, 16, 16]             256
           Conv2d-17          [-1, 128, 16, 16]           8,192
      BatchNorm2d-18          [-1, 128, 16, 16]             256
       BasicBlock-19          [-1, 128, 16, 16]               0
           Conv2d-20          [-1, 128, 16, 16]         147,456
      BatchNorm2d-21          [-1, 128, 16, 16]             256
           Conv2d-22          [-1, 128, 16, 16]         147,456
      BatchNorm2d-23          [-1, 128, 16, 16]             256
       BasicBlock-24          [-1, 128, 16, 16]               0
           Conv2d-25            [-1, 256, 8, 8]         294,912
      BatchNorm2d-26            [-1, 256, 8, 8]             512
           Conv2d-27            [-1, 256, 8, 8]         589,824
      BatchNorm2d-28            [-1, 256, 8, 8]             512
           Conv2d-29            [-1, 256, 8, 8]          32,768
      BatchNorm2d-30            [-1, 256, 8, 8]             512
       BasicBlock-31            [-1, 256, 8, 8]               0
           Conv2d-32            [-1, 256, 8, 8]         589,824
      BatchNorm2d-33            [-1, 256, 8, 8]             512
           Conv2d-34            [-1, 256, 8, 8]         589,824
      BatchNorm2d-35            [-1, 256, 8, 8]             512
       BasicBlock-36            [-1, 256, 8, 8]               0
           Conv2d-37            [-1, 512, 4, 4]       1,179,648
      BatchNorm2d-38            [-1, 512, 4, 4]           1,024
           Conv2d-39            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-40            [-1, 512, 4, 4]           1,024
           Conv2d-41            [-1, 512, 4, 4]         131,072
      BatchNorm2d-42            [-1, 512, 4, 4]           1,024
       BasicBlock-43            [-1, 512, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
       BasicBlock-48            [-1, 512, 4, 4]               0
           Linear-49                   [-1, 10]           5,130
================================================================
Total params: 11,173,962
Trainable params: 11,173,962
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.25
Params size (MB): 42.63
Estimated Total Size (MB): 53.89
----------------------------------------------------------------
EPOCH: 1
  0%|          | 0/391 [00:00<?, ?it/s]/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Loss=1.2065842151641846 Batch_id=390 Accuracy=51.92: 100%|██████████| 391/391 [01:23<00:00,  4.66it/s]
Test set: Average loss: 0.0100, Accuracy: 5585/10000 (55.85%)
Validation accuracy increased (0.000000 --> 55.850000).  Saving model ...
Learning rate = 0.01  for epoch:  2
EPOCH: 2
Loss=0.6696595549583435 Batch_id=390 Accuracy=69.82: 100%|██████████| 391/391 [01:37<00:00,  4.01it/s]
Test set: Average loss: 0.0076, Accuracy: 6745/10000 (67.45%)
Validation accuracy increased (55.850000 --> 67.450000).  Saving model ...
Learning rate = 0.01  for epoch:  3
EPOCH: 3
Loss=0.5865669250488281 Batch_id=390 Accuracy=76.88: 100%|██████████| 391/391 [01:40<00:00,  3.88it/s]
Test set: Average loss: 0.0081, Accuracy: 6641/10000 (66.41%)
Learning rate = 0.01  for epoch:  4
EPOCH: 4
Loss=0.4987580180168152 Batch_id=390 Accuracy=81.04: 100%|██████████| 391/391 [01:43<00:00,  3.79it/s]
Test set: Average loss: 0.0076, Accuracy: 6939/10000 (69.39%)
Validation accuracy increased (67.450000 --> 69.390000).  Saving model ...
Learning rate = 0.01  for epoch:  5
EPOCH: 5
Loss=0.516816258430481 Batch_id=390 Accuracy=83.31: 100%|██████████| 391/391 [01:45<00:00,  3.71it/s]
Test set: Average loss: 0.0057, Accuracy: 7624/10000 (76.24%)
Validation accuracy increased (69.390000 --> 76.240000).  Saving model ...
Learning rate = 0.01  for epoch:  6
EPOCH: 6
Loss=0.5572003126144409 Batch_id=390 Accuracy=85.54: 100%|██████████| 391/391 [01:41<00:00,  3.85it/s]
Test set: Average loss: 0.0058, Accuracy: 7628/10000 (76.28%)
Validation accuracy increased (76.240000 --> 76.280000).  Saving model ...
Learning rate = 0.01  for epoch:  7
EPOCH: 7
Loss=0.48829370737075806 Batch_id=390 Accuracy=87.22: 100%|██████████| 391/391 [01:42<00:00,  3.83it/s]
Test set: Average loss: 0.0050, Accuracy: 7941/10000 (79.41%)
Validation accuracy increased (76.280000 --> 79.410000).  Saving model ...
Learning rate = 0.01  for epoch:  8
EPOCH: 8
Loss=0.12157435715198517 Batch_id=390 Accuracy=88.33: 100%|██████████| 391/391 [01:43<00:00,  3.78it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.0068, Accuracy: 7395/10000 (73.95%)
Learning rate = 0.01  for epoch:  9
EPOCH: 9
Loss=0.2267511785030365 Batch_id=390 Accuracy=89.74: 100%|██████████| 391/391 [01:44<00:00,  3.74it/s]
Test set: Average loss: 0.0060, Accuracy: 7673/10000 (76.73%)
Epoch     9: reducing learning rate of group 0 to 1.0000e-03.
Learning rate = 0.001  for epoch:  10
EPOCH: 10
Loss=0.1669684797525406 Batch_id=390 Accuracy=93.68: 100%|██████████| 391/391 [01:42<00:00,  3.82it/s]
Test set: Average loss: 0.0035, Accuracy: 8558/10000 (85.58%)
Validation accuracy increased (79.410000 --> 85.580000).  Saving model ...
Learning rate = 0.001  for epoch:  11
EPOCH: 11
Loss=0.0942080095410347 Batch_id=390 Accuracy=94.86: 100%|██████████| 391/391 [01:42<00:00,  3.83it/s]
Test set: Average loss: 0.0036, Accuracy: 8595/10000 (85.95%)
Validation accuracy increased (85.580000 --> 85.950000).  Saving model ...
Learning rate = 0.001  for epoch:  12
EPOCH: 12
Loss=0.11977163702249527 Batch_id=390 Accuracy=95.37: 100%|██████████| 391/391 [01:39<00:00,  3.92it/s]
Test set: Average loss: 0.0036, Accuracy: 8602/10000 (86.02%)
Validation accuracy increased (85.950000 --> 86.020000).  Saving model ...
Epoch    12: reducing learning rate of group 0 to 1.0000e-04.
Learning rate = 0.0001  for epoch:  13
EPOCH: 13
Loss=0.05718041583895683 Batch_id=390 Accuracy=95.97: 100%|██████████| 391/391 [01:38<00:00,  3.98it/s]
Test set: Average loss: 0.0035, Accuracy: 8618/10000 (86.18%)
Validation accuracy increased (86.020000 --> 86.180000).  Saving model ...
Learning rate = 0.0001  for epoch:  14
EPOCH: 14
Loss=0.11011965572834015 Batch_id=390 Accuracy=96.03: 100%|██████████| 391/391 [01:38<00:00,  3.99it/s]
Test set: Average loss: 0.0036, Accuracy: 8611/10000 (86.11%)
Epoch    14: reducing learning rate of group 0 to 1.0000e-05.
Learning rate = 1e-05  for epoch:  15
EPOCH: 15
Loss=0.1493886411190033 Batch_id=390 Accuracy=96.13: 100%|██████████| 391/391 [01:35<00:00,  4.09it/s]
Test set: Average loss: 0.0035, Accuracy: 8633/10000 (86.33%)
Validation accuracy increased (86.180000 --> 86.330000).  Saving model ...
Learning rate = 1e-05  for epoch:  16
EPOCH: 16
Loss=0.08041713386774063 Batch_id=390 Accuracy=96.08: 100%|██████████| 391/391 [01:34<00:00,  4.14it/s]
Test set: Average loss: 0.0035, Accuracy: 8626/10000 (86.26%)
Epoch    16: reducing learning rate of group 0 to 1.0000e-06.
Learning rate = 1.0000000000000002e-06  for epoch:  17
EPOCH: 17
Loss=0.12399621307849884 Batch_id=390 Accuracy=96.15: 100%|██████████| 391/391 [01:37<00:00,  4.01it/s]
Test set: Average loss: 0.0035, Accuracy: 8619/10000 (86.19%)
Learning rate = 1.0000000000000002e-06  for epoch:  18
EPOCH: 18
Loss=0.1526818722486496 Batch_id=390 Accuracy=96.09: 100%|██████████| 391/391 [01:36<00:00,  4.07it/s]
Test set: Average loss: 0.0035, Accuracy: 8619/10000 (86.19%)
Epoch    18: reducing learning rate of group 0 to 1.0000e-07.
Learning rate = 1.0000000000000002e-07  for epoch:  19
EPOCH: 19
Loss=0.11698319017887115 Batch_id=390 Accuracy=96.15: 100%|██████████| 391/391 [01:44<00:00,  3.76it/s]
Test set: Average loss: 0.0036, Accuracy: 8613/10000 (86.13%)
Learning rate = 1.0000000000000002e-07  for epoch:  20
EPOCH: 20
Loss=0.12052084505558014 Batch_id=390 Accuracy=96.10: 100%|██████████| 391/391 [01:43<00:00,  3.79it/s]
Test set: Average loss: 0.0035, Accuracy: 8630/10000 (86.30%)
Epoch    20: reducing learning rate of group 0 to 1.0000e-08.
Learning rate = 1.0000000000000004e-08  for epoch:  21
EPOCH: 21
Loss=0.21197429299354553 Batch_id=390 Accuracy=96.15: 100%|██████████| 391/391 [01:43<00:00,  3.78it/s]
Test set: Average loss: 0.0034, Accuracy: 8631/10000 (86.31%)
Learning rate = 1.0000000000000004e-08  for epoch:  22
EPOCH: 22
Loss=0.09264859557151794 Batch_id=390 Accuracy=96.10: 100%|██████████| 391/391 [01:43<00:00,  3.79it/s]
Test set: Average loss: 0.0035, Accuracy: 8619/10000 (86.19%)
Learning rate = 1.0000000000000004e-08  for epoch:  23
EPOCH: 23
Loss=0.09461261332035065 Batch_id=390 Accuracy=96.25: 100%|██████████| 391/391 [01:49<00:00,  3.58it/s]
Test set: Average loss: 0.0035, Accuracy: 8636/10000 (86.36%)
Validation accuracy increased (86.330000 --> 86.360000).  Saving model ...
Learning rate = 1.0000000000000004e-08  for epoch:  24
EPOCH: 24
Loss=0.07259862869977951 Batch_id=390 Accuracy=96.11: 100%|██████████| 391/391 [01:41<00:00,  3.84it/s]
Test set: Average loss: 0.0036, Accuracy: 8607/10000 (86.07%)
Learning rate = 1.0000000000000004e-08  for epoch:  25
EPOCH: 25
Loss=0.19648469984531403 Batch_id=390 Accuracy=96.04: 100%|██████████| 391/391 [01:44<00:00,  3.74it/s]
Test set: Average loss: 0.0035, Accuracy: 8622/10000 (86.22%)
Learning rate = 1.0000000000000004e-08  for epoch:  26
Test Accuracy of airplane: 90% (1785/1962)
Test Accuracy of automobile: 89% (1770/1979)
Test Accuracy of  bird: 80% (1567/1958)
Test Accuracy of   cat: 72% (1441/1995)
Test Accuracy of  deer: 79% (1566/1960)
Test Accuracy of   dog: 70% (1391/1969)
Test Accuracy of  frog: 79% (1590/1995)
Test Accuracy of horse: 88% (1771/1993)
Test Accuracy of  ship: 77% (1526/1976)
Test Accuracy of truck: 81% (1603/1963)
Test Accuracy (Overall): 81% (16010/19750)
Traceback (most recent call last):
  File "/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3319, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-2-e314348aba92>", line 1, in <module>
    runfile('/home/abhijit/EVARepo/EVA/A8/a8.py', wdir='/home/abhijit/EVARepo/EVA/A8')
  File "/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File "/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/abhijit/EVARepo/EVA/A8/a8.py", line 70, in <module>
    plotdata.PlotData.plotmisclassifiedimages(dataiterator=dataiterator, model=cnn_model, classes=classes)
  File "/home/abhijit/EVARepo/EVA/A8/src/visualization/plotdata.py", line 47, in plotmisclassifiedimages
    plt.savefig(".images/missclassifiedimages.png")
  File "/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/matplotlib/pyplot.py", line 722, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/matplotlib/figure.py", line 2180, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/matplotlib/backend_bases.py", line 2089, in print_figure
    **kwargs)
  File "/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py", line 530, in print_png
    cbook.open_file_cm(filename_or_obj, "wb") as fh:
  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__
    return next(self.gen)
  File "/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/matplotlib/cbook/__init__.py", line 447, in open_file_cm
    fh, opened = to_filehandle(path_or_file, mode, True, encoding)
  File "/home/abhijit/.virtualenvs/dl4cv/lib/python3.6/site-packages/matplotlib/cbook/__init__.py", line 432, in to_filehandle
    fh = open(fname, flag, encoding=encoding)
FileNotFoundError: [Errno 2] No such file or directory: '.images/missclassifiedimages.png'

